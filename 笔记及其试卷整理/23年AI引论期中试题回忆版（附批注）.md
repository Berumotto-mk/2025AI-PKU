# 2023春季AI引论期中试题回忆版 #信科 xk 原神

### 一、KNN

1. KNN的优缺点有哪些？

- 优点：简单，易用
	- 不需要训练
- 缺点：对于高维度会出现纸度灾难
	- 需要储存所有的训练样本
	- 在测试时需要计算测试样本到所有训练样本的距离
	- 有时候很难找到一个好的距离函数

2. 给你五个数据(x_i, y_i)，分别用1-NN, 3-NN, 5-NN预测(x*)的类别。

- 1-NN,3-NN
- k-NN定义：离训练样本中距离它最近的k个样本（默认欧式距离）

3. 修改KNN算法，距离为d的权重为2^(-d)，用5-NN重新预测(x*)的类别。

- 

### 二、原神抽卡（概率统计）

（前73抽出金概率0.006，74及之后每抽概率增加0.994/17）

1. 求恰好74抽出金的概率

- $(1-0.9940)^{73} \times (0.994+0.994/17)$

2. 已知75抽内出金，求73抽内出金的概率（条件概率）

3. 恰好第几抽出金概率最大？

4. 已知第三个金是UP，求第三个金是大保底的概率

### 三、最大似然估计

1. 设P(x=1|y=0)=1-a， P(x=1|y=1)=a，n个样本中m个满足x_i≠y_i，求a的MLE

- $\max ((1-a)^m\times(a)^{m-n} )$



2. 若m=n/2，且有n/2个样本满足x_i=1，且有n/2个样本满足y_i=1，再设P(y=0)=a，求a的MLE

- p(y=1) = 1-a
- ？

### 四、神经网络

1. 若score1=w_1^Tx+b1^  ,  score2=w_2^Tx+b2^，用softmax二分类，求P(y=1|x)，并证明这个与sigmoid等价



2. 给你一个神经网络y=sigmoid(w21*relu(w11x+b11)*+w22relu(w12x+b12)+b2)，和w, x的值，求各个中间值和y的值



3. 若真实值y=1，对上述神经网络求NCE loss对x和各个中间值的导数

- NCE Loss（Noise Contrastive Estimation Loss，噪声对比估计损失）是一种用于机器学习的损失函数(课上好像没学过)

- $$
	\mathcal{L} = -\log \sigma(s(x, y)) - \sum_{j=1}^{k} \log \sigma(-s(x, y_j))
	$$



### 五、MCTS(类似Lecture9棋类)

1. 给你一个建好的MCTS树(已知各节点q,n)，估值函数A=q/n+0.2*(ln(n_parent)/n)，求这次选中的叶子节点

- 

2. 若这次模拟赢了(q=1)，求向上传播过程

- 

### 六、扫雷



1. 用CNF描述扫雷，变量的含义自己设

- 

2. 3*3扫雷，分别写出深搜和广搜过程

- 

4. 4*4扫雷，写出带有顺序优化+边一致性的搜索过程

5. 扫雷可以用哪个启发函数？解释你的答案

### 七、HOG

1. 定义水平梯度为(右上-左上)+2*(右-左)+(右下-左下)，垂直梯度同理。算图上四个点的梯度模长，以及图上四个点的梯度方向

- 图像在平面上用f(x,y)来表示

2. 算一些concat后的聚合梯度，各个方向区间的梯度模长之和